services:
  ai-toolkit:
    build: .
    image: ai-toolkit:latest
    container_name: ai-toolkit
    environment:
      # Disable torch.compile/inductor - Triton doesn't support Blackwell sm_121a yet
      TORCH_COMPILE_DISABLE: "1"
      TORCHDYNAMO_DISABLE: "1"

      # Grace-Blackwell unified memory optimizations
      CUDA_CACHE_DISABLE: "1"
      PYTORCH_NO_CUDA_MEMORY_CACHING: "1"
      CUDA_DEVICE_MAX_CONNECTIONS: "1"
      CUDA_DEVICE_MAX_COPY_CONNECTIONS: "4"
      CUDA_MODULE_LOADING: "EAGER"
      #CUDA_MANAGED_FORCE_DEVICE_ALLOC: "1"
      OMP_NUM_THREADS: "20"
      CUBLAS_WORKSPACE_CONFIG: ":0:0"
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./config:/app/config
      - ~/gb10/models/comfyui/diffusion_models:/models
      - ~/gb10/images/bb_images/S10E02:/input
      #- ~/gb10/images/bb_images_test:/input
      - ~/gb10/output_models:/output
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    shm_size: 16gb
    mem_limit: 115g
    memswap_limit: 115g
    stdin_open: true
    tty: true
    command: ["python", "run.py", "config/testbb.yaml"]
