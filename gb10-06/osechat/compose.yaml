services:
    osechat:
        build:
            context: .
            dockerfile: Dockerfile
        container_name: osechat
        ports:
            - "8005:8000"
        volumes:
            # Mount app.py for live development - no rebuild needed
            - ./app.py:/app/app.py
        environment:
            - OLLAMA_BASE_URL=http://ollama:11434/v1
            - OLLAMA_MODEL=gpt-oss:20b
            - PYTHONDONTWRITEBYTECODE=1
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [gpu]
        # Restart policy
        restart: unless-stopped
        command: chainlit run app.py --host 0.0.0.0 --port 8000 --watch --debug
        networks:
            - ai-network

networks:
    ai-network:
        name: ai-network
        driver: bridge

# volumes:
#   ollama_data:
